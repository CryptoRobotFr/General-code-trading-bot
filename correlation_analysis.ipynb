{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import ccxt.async_support as ccxt\n",
    "import aiohttp\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Set\n",
    "from dataclasses import dataclass\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CONSTANTS ====================\n",
    "COINGECKO_API_URL = \"https://api.coingecko.com/api/v3\"\n",
    "STABLECOINS = {\n",
    "    'USDT', 'USDC', 'BUSD', 'DAI', 'TUSD', 'USDP', 'USDD', 'SUSD0', 'PYUSD', 'USDX', 'USR', 'HONEY', 'USDD'\n",
    "    'FDUSD', 'USDJ', 'USDD', 'GUSD', 'FRAX', 'USDS', 'USDE', 'USDX', 'SUSDS', 'USDC.E', 'USDB', 'BUIDL', 'USDY', 'USDA', 'GHO',\n",
    "}\n",
    "CLONECOINS = {\n",
    "    'STETH', 'WBTC', 'WSTETH', 'WETH', 'WEETH', 'CBBTC', 'LBTC', 'RSETH', 'SOLVBTC', 'RETH', 'METH', 'BNSOL', \n",
    "    'SOLVBTC.BBN', 'EZETH', 'WBNB', 'MSOL', 'CMETH', 'JUPSOL'\n",
    "}\n",
    "\n",
    "# ==================== RATE LIMITER ====================\n",
    "class RateLimiter:\n",
    "    def __init__(self, rate_limit: int = 100):\n",
    "        self.rate_limit = rate_limit\n",
    "        self.last_request_time = 0\n",
    "    \n",
    "    async def wait(self) -> None:\n",
    "        current_time = time.time() * 1000\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        wait_time = max(0, (1000 / self.rate_limit) - time_since_last)\n",
    "        \n",
    "        if wait_time > 0:\n",
    "            await asyncio.sleep(wait_time / 1000)\n",
    "            \n",
    "        self.last_request_time = time.time() * 1000\n",
    "\n",
    "# ==================== COINGECKO API ====================\n",
    "class CoinGeckoAPI:\n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        self.api_url = COINGECKO_API_URL\n",
    "        self.api_key = api_key\n",
    "        self.rate_limiter = RateLimiter(10)\n",
    "        self.session = None\n",
    "        \n",
    "    async def __aenter__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        return self\n",
    "        \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.session is not None:\n",
    "            await self.session.close()\n",
    "            \n",
    "    async def get_coins_markets(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        await self.rate_limiter.wait()\n",
    "        \n",
    "        url = f\"{self.api_url}/coins/markets\"\n",
    "        query_params = {\n",
    "            'vs_currency': 'usd',\n",
    "            'order': 'market_cap_desc',\n",
    "            'per_page': params.get('per_page', 250),\n",
    "            'page': params.get('page', 1),\n",
    "            'sparkline': 'false',\n",
    "        }\n",
    "        \n",
    "        headers = {}\n",
    "        if self.api_key:\n",
    "            headers['x-cg-pro-api-key'] = self.api_key\n",
    "            \n",
    "        try:\n",
    "            async with self.session.get(url, params=query_params, headers=headers) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to fetch data from CoinGecko: {str(e)}\")\n",
    "\n",
    "# ==================== EXCHANGE WRAPPER ====================\n",
    "class CcxtExchange:\n",
    "    def __init__(self, exchange_name: str, **configs: Dict[str, Any]):\n",
    "        exchange_class = getattr(ccxt, exchange_name)\n",
    "        \n",
    "        self._client = exchange_class({\n",
    "            'apiKey': configs.get(\"api_key\"),\n",
    "            'secret': configs.get(\"api_secret\"),\n",
    "            'enableRateLimit': True,\n",
    "            **(configs.get(\"options\", {}))\n",
    "        })\n",
    "        \n",
    "        self._exchange_name = exchange_name\n",
    "        self._limit_size = configs.get(\"limit_size\", 1000)\n",
    "        self._rate_limiter = RateLimiter(configs.get(\"rate_limit\", 100))\n",
    "        self._markets = None\n",
    "        self._supported_pairs = set()\n",
    "        self._timeframe_ms = {\n",
    "            \"1m\": 60 * 1000,\n",
    "            \"5m\": 5 * 60 * 1000,\n",
    "            \"15m\": 15 * 60 * 1000,\n",
    "            \"30m\": 30 * 60 * 1000,\n",
    "            \"1h\": 60 * 60 * 1000,\n",
    "            \"4h\": 4 * 60 * 60 * 1000,\n",
    "            \"1d\": 24 * 60 * 60 * 1000,\n",
    "            \"1w\": 7 * 24 * 60 * 60 * 1000,\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def exchange_name(self) -> str:\n",
    "        return self._exchange_name\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        await self._ensure_markets_loaded()\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        await self.close()\n",
    "    \n",
    "    async def _ensure_markets_loaded(self) -> None:\n",
    "        try:\n",
    "            if not self._markets:\n",
    "                await self._rate_limiter.wait()\n",
    "                self._markets = await self._client.load_markets()\n",
    "                self._supported_pairs = set(self._markets.keys())\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error loading markets for {self._exchange_name}: {str(e)}\")\n",
    "    \n",
    "    async def fetch_ohlcv(self, pair: str, timeframe: str, since: int, limit: int) -> List[List[Any]]:\n",
    "        try:\n",
    "            await self._ensure_markets_loaded()\n",
    "            \n",
    "            if pair not in self._supported_pairs:\n",
    "                raise Exception(f\"Pair {pair} not available on {self._exchange_name}\")\n",
    "                \n",
    "            await self._rate_limiter.wait()\n",
    "            return await self._client.fetch_ohlcv(pair, timeframe, since, limit)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error fetching OHLCV data for {pair} - {timeframe}: {str(e)}\")\n",
    "    \n",
    "    def get_supported_pairs(self) -> set:\n",
    "        return self._supported_pairs\n",
    "    \n",
    "    def get_timeframe_milliseconds(self, timeframe: str) -> int:\n",
    "        return self._timeframe_ms.get(timeframe, 24 * 60 * 60 * 1000)\n",
    "    \n",
    "    def get_ohlcv_request_limit(self) -> int:\n",
    "        return self._limit_size\n",
    "    \n",
    "    async def close(self) -> None:\n",
    "        await self._client.close()\n",
    "\n",
    "# ==================== OHLCV DOWNLOADER ====================\n",
    "@dataclass(frozen=True)\n",
    "class OhlcvDataPoint:\n",
    "    pair: str\n",
    "    timeframe: str\n",
    "    start_date: Optional[datetime] = None\n",
    "    end_date: Optional[datetime] = None\n",
    "\n",
    "class OhlcvDownloader:\n",
    "    def __init__(self, exchange: CcxtExchange):\n",
    "        self._exchange = exchange\n",
    "    \n",
    "    async def download_pair(self, request: OhlcvDataPoint) -> pd.DataFrame:\n",
    "        try:\n",
    "            interval_ms = self._exchange.get_timeframe_milliseconds(request.timeframe)\n",
    "            chunk_size = self._exchange.get_ohlcv_request_limit()\n",
    "            \n",
    "            end_ts = int(datetime.now().timestamp() * 1000) if request.end_date is None else int(request.end_date.timestamp() * 1000)\n",
    "            \n",
    "            if request.start_date is None:\n",
    "                start_ts = end_ts - (30 * 24 * 60 * 60 * 1000)\n",
    "            else:\n",
    "                start_ts = int(request.start_date.timestamp() * 1000)\n",
    "                \n",
    "            print(f\"Downloading {request.pair} - {request.timeframe}...\")\n",
    "            return await self._download_data(request, start_ts, end_ts, chunk_size, interval_ms)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {request.pair} - {request.timeframe}: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    async def _download_data(self, request: OhlcvDataPoint, start_ts: int, end_ts: int, \n",
    "                           chunk_size: int, interval_ms: int) -> pd.DataFrame:\n",
    "        tasks = []\n",
    "        current_ts = start_ts\n",
    "        \n",
    "        while current_ts < end_ts:\n",
    "            task = asyncio.create_task(\n",
    "                self._fetch_chunk(request, current_ts, chunk_size)\n",
    "            )\n",
    "            tasks.append(task)\n",
    "            current_ts += interval_ms * chunk_size\n",
    "        \n",
    "        chunks = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        valid_chunks = [chunk for chunk in chunks if isinstance(chunk, pd.DataFrame) and not chunk.empty]\n",
    "        \n",
    "        if not valid_chunks:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        data = pd.concat(valid_chunks)\n",
    "        data['date'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "        data = data.set_index('date')\n",
    "        data = data.drop(columns=['timestamp'])\n",
    "        data = data[~data.index.duplicated(keep='last')].sort_index()\n",
    "        \n",
    "        if request.start_date:\n",
    "            data = data[data.index >= pd.Timestamp(request.start_date)]\n",
    "        if request.end_date:\n",
    "            data = data[data.index <= pd.Timestamp(request.end_date)]\n",
    "            \n",
    "        return data\n",
    "\n",
    "    async def _fetch_chunk(self, request: OhlcvDataPoint, timestamp: int, chunk_size: int) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = await self._exchange.fetch_ohlcv(\n",
    "                pair=request.pair,\n",
    "                timeframe=request.timeframe,\n",
    "                since=timestamp,\n",
    "                limit=chunk_size,\n",
    "            )\n",
    "            return pd.DataFrame(\n",
    "                data, columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {request.pair} - {request.timeframe} at {timestamp}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# ==================== HELPER FUNCTIONS ====================\n",
    "def calculate_pct_returns(df: pd.DataFrame, price_columns: List[str]) -> pd.DataFrame:\n",
    "    returns_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for col in price_columns:\n",
    "        if col in df.columns:\n",
    "            returns_df[col] = df[col].pct_change()\n",
    "    \n",
    "    returns_df = returns_df.dropna()\n",
    "    return returns_df\n",
    "\n",
    "def compute_correlation_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    return df.corr(method='pearson')\n",
    "\n",
    "def simplify_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    rename_map = {}\n",
    "    for col in df_copy.columns:\n",
    "        match = re.match(r'([^/]+)/', col)\n",
    "        if match:\n",
    "            rename_map[col] = match.group(1)\n",
    "    \n",
    "    df_copy.rename(columns=rename_map, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "def plot_heatmap(corr_matrix: pd.DataFrame, title: str = \"Correlation Matrix\", \n",
    "                 figsize: Tuple[int, int] = (12, 10), cmap: str = \"coolwarm\",\n",
    "                 annot: bool = True, mask_upper: bool = True,\n",
    "                 simplify_names: bool = True) -> None:\n",
    "    if simplify_names:\n",
    "        corr_matrix = corr_matrix.copy()\n",
    "        rename_map = {}\n",
    "        for col in corr_matrix.columns:\n",
    "            match = re.match(r'([^/]+)/', col)\n",
    "            if match:\n",
    "                rename_map[col] = match.group(1)\n",
    "        \n",
    "        corr_matrix = corr_matrix.rename(columns=rename_map, index=rename_map)\n",
    "    \n",
    "    mask = None\n",
    "    if mask_upper:\n",
    "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0,\n",
    "               center=0, annot=annot, fmt=\".2f\", square=True, linewidths=.5)\n",
    "    \n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_sorted_correlations(corr_matrix: pd.DataFrame, threshold: float = 0.0,\n",
    "                           direction: str = \"above\", exclude_self: bool = True,\n",
    "                           simplify_names: bool = True) -> pd.DataFrame:\n",
    "    if simplify_names:\n",
    "        corr_matrix = simplify_column_names(corr_matrix)\n",
    "    \n",
    "    corr_pairs = corr_matrix.unstack()\n",
    "    \n",
    "    if simplify_names:\n",
    "        corr_pairs.index = [f\"{i[0]} - {i[1]}\" for i in corr_pairs.index]\n",
    "    else:\n",
    "        corr_pairs.index = [\n",
    "            f\"{re.match(r'([^/]+)/', i[0]).group(1) if re.match(r'([^/]+)/', i[0]) else i[0]} - \"\n",
    "            f\"{re.match(r'([^/]+)/', i[1]).group(1) if re.match(r'([^/]+)/', i[1]) else i[1]}\" \n",
    "            for i in corr_pairs.index\n",
    "        ]\n",
    "    \n",
    "    corr_df = pd.DataFrame(corr_pairs, columns=[\"correlation\"])\n",
    "    \n",
    "    if threshold > 0:\n",
    "        if direction.lower() == \"above\":\n",
    "            corr_df = corr_df[corr_df[\"correlation\"] >= threshold]\n",
    "        elif direction.lower() == \"below\":\n",
    "            corr_df = corr_df[corr_df[\"correlation\"] <= threshold]\n",
    "        else:\n",
    "            corr_df = corr_df[abs(corr_df[\"correlation\"]) >= threshold]\n",
    "    \n",
    "    if exclude_self:\n",
    "        corr_df = corr_df[abs(corr_df[\"correlation\"]) < 1.0]\n",
    "    \n",
    "    if direction.lower() == \"above\":\n",
    "        return corr_df.sort_values(by=\"correlation\", ascending=False)\n",
    "    elif direction.lower() == \"below\":\n",
    "        return corr_df.sort_values(by=\"correlation\", ascending=True)\n",
    "    else:\n",
    "        return corr_df.sort_values(by=\"correlation\", key=abs, ascending=False)\n",
    "\n",
    "# ==================== CRYPTO ANALYSIS MODULE ====================\n",
    "class CryptoCorrelationAnalysis:\n",
    "    def __init__(self, exchange_name: str = \"binance\", api_key: Optional[str] = None):\n",
    "        self.exchange_name = exchange_name\n",
    "        self.api_key = api_key\n",
    "        self.selected_pairs = []\n",
    "        self.data = {}\n",
    "    \n",
    "    async def select_pairs(self, top_n: int = 20, quote_currency: str = \"USDT\",\n",
    "                         remove_stablecoins: bool = True, remove_clones: bool = True,\n",
    "                         add_pairs: Optional[List[str]] = None,\n",
    "                         remove_pairs: Optional[List[str]] = None) -> List[str]:\n",
    "        async with CoinGeckoAPI(api_key=self.api_key) as client:\n",
    "            params = {\n",
    "                'per_page': 250,\n",
    "                'page': 1,\n",
    "                'order': 'market_cap_desc'\n",
    "            }\n",
    "            data = await client.get_coins_markets(params)\n",
    "            \n",
    "            df = pd.DataFrame([{\n",
    "                'id': coin['id'],\n",
    "                'name': coin['name'],\n",
    "                'symbol': coin['symbol'].upper(),\n",
    "                'market_cap': coin['market_cap'],\n",
    "                'market_cap_rank': coin['market_cap_rank']\n",
    "            } for coin in data])\n",
    "            \n",
    "            if remove_stablecoins:\n",
    "                df = df[~df['symbol'].isin(STABLECOINS)]\n",
    "            \n",
    "            if remove_clones:\n",
    "                df = df[~df['symbol'].isin(CLONECOINS)]\n",
    "                \n",
    "            df = df.sort_values('market_cap_rank', ascending=True)\n",
    "            df = df.head(top_n)\n",
    "            \n",
    "            pairs = [f\"{row['symbol'].upper()}/{quote_currency}\" for _, row in df.iterrows()]\n",
    "        \n",
    "        pairs_set = set(pairs)\n",
    "        \n",
    "        if add_pairs:\n",
    "            for pair in add_pairs:\n",
    "                pairs_set.add(pair)\n",
    "                \n",
    "        if remove_pairs:\n",
    "            for pair in remove_pairs:\n",
    "                if pair in pairs_set:\n",
    "                    pairs_set.remove(pair)\n",
    "                    \n",
    "        pairs = sorted(list(pairs_set))\n",
    "        \n",
    "        self.selected_pairs = pairs\n",
    "        return pairs\n",
    "    \n",
    "    async def download_ohlcv(self, pairs: Optional[List[str]] = None,\n",
    "                            timeframes: Union[str, List[str]] = \"1d\",\n",
    "                            start_date: Optional[Union[str, datetime]] = None,\n",
    "                            end_date: Optional[Union[str, datetime]] = None) -> Dict[str, Dict[str, pd.DataFrame]]:\n",
    "        if pairs is None:\n",
    "            if not self.selected_pairs:\n",
    "                raise ValueError(\"No pairs selected. Call select_pairs() first or provide pairs explicitly.\")\n",
    "            pairs = self.selected_pairs\n",
    "        \n",
    "        if isinstance(timeframes, str):\n",
    "            timeframes = [timeframes]\n",
    "            \n",
    "        if isinstance(start_date, str):\n",
    "            start_date = datetime.fromisoformat(start_date.replace('Z', '+00:00'))\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = datetime.fromisoformat(end_date.replace('Z', '+00:00'))\n",
    "            \n",
    "        exchange = CcxtExchange(self.exchange_name)\n",
    "        downloader = OhlcvDownloader(exchange)\n",
    "        \n",
    "        result_data = {tf: {} for tf in timeframes}\n",
    "        \n",
    "        async with exchange:\n",
    "            for timeframe in timeframes:\n",
    "                for pair in pairs:\n",
    "                    request = OhlcvDataPoint(\n",
    "                        pair=pair,\n",
    "                        timeframe=timeframe,\n",
    "                        start_date=start_date,\n",
    "                        end_date=end_date\n",
    "                    )\n",
    "                    \n",
    "                    df = await downloader.download_pair(request)\n",
    "                    \n",
    "                    if not df.empty:\n",
    "                        result_data[timeframe][pair] = df\n",
    "                \n",
    "                if timeframe in result_data and result_data[timeframe]:\n",
    "                    self.data[timeframe] = result_data[timeframe]\n",
    "        \n",
    "        return result_data\n",
    "    \n",
    "    async def load_ohlcv(self, pairs: Optional[List[str]] = None, timeframe: str = \"1d\",\n",
    "                       start_date: Optional[Union[str, datetime]] = None,\n",
    "                       end_date: Optional[Union[str, datetime]] = None,\n",
    "                       price_type: Union[str, List[str]] = \"close\",\n",
    "                       calculate_returns: bool = False) -> Dict[str, pd.DataFrame]:\n",
    "        if pairs is None:\n",
    "            if not self.selected_pairs:\n",
    "                raise ValueError(\"No pairs selected. Call select_pairs() first or provide pairs explicitly.\")\n",
    "            pairs = self.selected_pairs\n",
    "            \n",
    "        if timeframe not in self.data:\n",
    "            raise ValueError(f\"No data available for timeframe {timeframe}. Call download_ohlcv() first.\")\n",
    "        \n",
    "        if isinstance(price_type, str):\n",
    "            price_type = [price_type]\n",
    "        \n",
    "        if isinstance(start_date, str):\n",
    "            start_date = datetime.fromisoformat(start_date.replace('Z', '+00:00'))\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = datetime.fromisoformat(end_date.replace('Z', '+00:00'))\n",
    "            \n",
    "        all_data = {}\n",
    "        price_columns = []\n",
    "        \n",
    "        for pair in pairs:\n",
    "            if pair in self.data[timeframe]:\n",
    "                df = self.data[timeframe][pair]\n",
    "                \n",
    "                if start_date:\n",
    "                    df = df[df.index >= pd.Timestamp(start_date)]\n",
    "                if end_date:\n",
    "                    df = df[df.index <= pd.Timestamp(end_date)]\n",
    "                \n",
    "                for col in price_type:\n",
    "                    if col in df.columns:\n",
    "                        col_name = f\"{pair}_{col}\"\n",
    "                        all_data[col_name] = df[col]\n",
    "                        price_columns.append(col_name)\n",
    "        \n",
    "        result = {}\n",
    "        if all_data:\n",
    "            prices_df = pd.DataFrame(all_data)\n",
    "            result[\"prices\"] = prices_df\n",
    "            \n",
    "            if calculate_returns and not prices_df.empty:\n",
    "                result[\"returns\"] = calculate_pct_returns(prices_df, price_columns)\n",
    "        else:\n",
    "            result[\"prices\"] = pd.DataFrame()\n",
    "            if calculate_returns:\n",
    "                result[\"returns\"] = pd.DataFrame()\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    async def get_data(self, top_n: int = 20, quote_currency: str = \"USDT\",\n",
    "                     timeframe: str = \"1d\", start_date: Optional[Union[str, datetime]] = None,\n",
    "                     end_date: Optional[Union[str, datetime]] = None,\n",
    "                     remove_stablecoins: bool = True, remove_clones: bool = True,\n",
    "                     price_type: Union[str, List[str]] = \"close\",\n",
    "                     calculate_returns: bool = True,\n",
    "                     custom_pairs: Optional[List[str]] = None,\n",
    "                     add_pairs: Optional[List[str]] = None,\n",
    "                     remove_pairs: Optional[List[str]] = None) -> Dict[str, pd.DataFrame]:\n",
    "        if custom_pairs:\n",
    "            self.selected_pairs = custom_pairs\n",
    "        else:\n",
    "            await self.select_pairs(\n",
    "                top_n=top_n,\n",
    "                quote_currency=quote_currency,\n",
    "                remove_stablecoins=remove_stablecoins,\n",
    "                remove_clones=remove_clones,\n",
    "                add_pairs=add_pairs,\n",
    "                remove_pairs=remove_pairs\n",
    "            )\n",
    "        \n",
    "        await self.download_ohlcv(\n",
    "            timeframes=timeframe,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date\n",
    "        )\n",
    "        \n",
    "        return await self.load_ohlcv(\n",
    "            timeframe=timeframe,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            price_type=price_type,\n",
    "            calculate_returns=calculate_returns\n",
    "        )\n",
    "    \n",
    "    def analyse(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        threshold: float = 0.0,\n",
    "        direction: str = \"above\",\n",
    "        plot: bool = True,\n",
    "        title: str = \"Correlation Matrix\",\n",
    "        figsize: Tuple[int, int] = (12, 10),\n",
    "        simplify_names: bool = True\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        corr_matrix = compute_correlation_matrix(data)\n",
    "        sorted_corrs = get_sorted_correlations(\n",
    "            corr_matrix, \n",
    "            threshold=threshold,\n",
    "            direction=direction,\n",
    "            simplify_names=simplify_names\n",
    "        )\n",
    "            \n",
    "       \n",
    "        if plot:\n",
    "            plot_heatmap(\n",
    "                corr_matrix,\n",
    "                title=title, \n",
    "                figsize=figsize, \n",
    "                simplify_names=simplify_names\n",
    "            )\n",
    "        \n",
    "        return corr_matrix, sorted_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = CryptoCorrelationAnalysis(exchange_name=\"binance\") # L'exchange sur lequel on va récupérer les données\n",
    "result = await analysis.get_data(\n",
    "    top_n=15,                                      # Nombre de cryptomonnaies à sélectionner par capitalisation boursière\n",
    "    timeframe=\"1d\",                                # Intervalle de temps pour les données (1 heure)\n",
    "    start_date=\"2025-01-01\",                       # Date de début pour la collecte des données\n",
    "    end_date=\"2025-03-01\",                         # Date de fin pour la collecte des données\n",
    "    add_pairs=[],                                  # Paires supplémentaires à ajouter (liste vide ici)\n",
    "    remove_pairs=[\"BGB/USDT\", \"HYPE/USDT\", \"LEO/USDT\", \"PI/USDT\", \"ONDO/USDT\"],  # Paires à exclure\n",
    ")\n",
    "\n",
    "print(f\"Nombre de paires sélectionnées: {len(analysis.selected_pairs)}\")\n",
    "print(f\"Paires sélectionnées: {analysis.selected_pairs}\")\n",
    "print(f\"\\nAperçu des prix:\")\n",
    "display(result[\"prices\"].head())\n",
    "print(f\"\\nAperçu des rendements:\")\n",
    "display(result[\"returns\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix, sorted_corrs = analysis.analyse(\n",
    "    result[\"returns\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
